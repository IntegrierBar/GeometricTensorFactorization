{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0652d-cd37-44d4-bdae-74e1ce254671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my code\n",
    "from tensorfactorization.utils import (defactorizing_CP, create_initial_data, random_cp_with_noise)\n",
    "from tensorfactorization.multiplicative import (tensor_factorization_cp_multiplicative, tensor_factorization_cp_multiplicative_poisson)\n",
    "from tensorfactorization.poisson import (BacktrackingWarning, tensor_factorization_cp_poisson, tensor_factorization_cp_poisson_fixed_step_size)\n",
    "\n",
    "from toolkit.constants import (\n",
    "    picture_folder, data_folder, \n",
    "    error_label, iteration_label, tensor_dimension_label, time_label, \n",
    "    xscale_convergence_data, xscale_convergence, yscale_convergence\n",
    ")\n",
    "from toolkit.classes import (\n",
    "    IterationResult,\n",
    "    Factorizer\n",
    ")\n",
    "from toolkit.evaluate import (\n",
    "    evaluate_algorithms\n",
    ")\n",
    "\n",
    "#%matplotlib widget\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # use pickle to save results to disk\n",
    "import warnings\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e8393-83d2-4e87-89ae-adb5887f12ce",
   "metadata": {},
   "source": [
    "## Evaluate All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d85387-32d6-4384-88e9-79037f5e86dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on random generated tensors:\n",
      "Dimension of tensor: (10, 10, 10), noise: 0.008538784204012564, F: 3, norm: 1.8769195739237619\n",
      "Multiplicative converged in 1.165 seconds and 1140 iterations\n",
      "Multiplicative Poisson converged in 1.381 seconds and 921 iterations\n",
      "Geometric step size calculation without rescaling converged in 0.885 seconds and 220 iterations\n",
      "Geometric step size calculation with normalization converged in 1.319 seconds and 332 iterations\n",
      "Geometric step size calculation with max = 1 converged in 1.282 seconds and 225 iterations\n",
      "Geometric step size calculation with mean = 1 converged in 1.360 seconds and 214 iterations\n",
      "Geometric fixed step size converged in 3.806 seconds and 2001 iterations\n",
      "Dimension of tensor: (20, 20, 5), noise: 0.07644444279516903, F: 5, norm: 8.828232239244514\n",
      "Multiplicative converged in 1.802 seconds and 2001 iterations\n",
      "Multiplicative Poisson converged in 4.361 seconds and 1860 iterations\n",
      "Geometric step size calculation without rescaling converged in 1.242 seconds and 222 iterations\n",
      "Geometric step size calculation with normalization converged in 1.175 seconds and 263 iterations\n",
      "Geometric step size calculation with max = 1 converged in 1.449 seconds and 216 iterations\n",
      "Geometric step size calculation with mean = 1 converged in 1.067 seconds and 170 iterations\n",
      "Geometric fixed step size converged in 3.511 seconds and 2001 iterations\n",
      "Dimension of tensor: (10, 10, 10, 5), noise: 0, F: 5, norm: 187.28871167756031\n",
      "Multiplicative converged in 1.365 seconds and 1209 iterations\n",
      "Multiplicative Poisson converged in 3.122 seconds and 980 iterations\n",
      "Geometric step size calculation without rescaling converged in 4.140 seconds and 416 iterations\n",
      "Geometric step size calculation with normalization converged in 1.576 seconds and 325 iterations\n",
      "Geometric step size calculation with max = 1 converged in 2.424 seconds and 308 iterations\n",
      "Geometric step size calculation with mean = 1 converged in 2.877 seconds and 306 iterations\n"
     ]
    }
   ],
   "source": [
    "# CREATE FACTORIZER OBJECTS FOR ALL ALGORITHMS\n",
    "max_iter = 2000\n",
    "\n",
    "# The standart multiplicative algorithm\n",
    "def multiplicative_factorization(tensor, F, initial_A_ns):\n",
    "    start = time.time()\n",
    "    A_ns, RE, _ = tensor_factorization_cp_multiplicative(tensor, F, max_iter=max_iter, detailed=True, initial_A_ns=initial_A_ns)\n",
    "    end = time.time()\n",
    "    return IterationResult(tl.tensor(RE), end-start, A_ns)\n",
    "factorizer_multiplicative = Factorizer(\"Multiplicative\", multiplicative_factorization, color='red')\n",
    "\n",
    "# The Poisson variant of the multiplicative algorithm\n",
    "def multiplicative_poisson_factorization(tensor, F, initial_A_ns):\n",
    "    start = time.time()\n",
    "    A_ns, RE, _ = tensor_factorization_cp_multiplicative_poisson(tensor, F, max_iter=max_iter, detailed=True, initial_A_ns=initial_A_ns)\n",
    "    end = time.time()\n",
    "    return IterationResult(tl.tensor(RE), end-start, A_ns)\n",
    "factorizer_multiplicative_poisson = Factorizer(\"Multiplicative Poisson\", multiplicative_poisson_factorization, color='orange')\n",
    "\n",
    "\n",
    "# The new geometric algorithm with step size calculation and without any form of normalization\n",
    "def geometric_variable_step_size(tensor, F, initial_A_ns):\n",
    "    start = time.time()\n",
    "    A_ns, RE, _, _ = tensor_factorization_cp_poisson(tensor, F, max_iter=max_iter, detailed=True, verbose=False, initial_A_ns=initial_A_ns)\n",
    "    end = time.time()\n",
    "    return IterationResult(tl.tensor(RE), end-start, A_ns)\n",
    "factorizer_geometric = Factorizer(\"Geometric step size calculation without rescaling\", geometric_variable_step_size, color='blue')\n",
    "\n",
    "# The new geometric algorithm with step size calculation and but normalization of the tensor and the initial data\n",
    "def geometric_variable_normalized(tensor, F, initial_A_ns):\n",
    "    # copy tensor and initial data and rescale\n",
    "    norm_of_tensor = tl.norm(tensor)\n",
    "    tensor_copy = tensor / norm_of_tensor # normalize tensor\n",
    "    norm_of_approximation = tl.norm(defactorizing_CP(initial_A_ns, tensor.shape))\n",
    "    initial_A_ns_copy = deepcopy(initial_A_ns)\n",
    "    scaling = (1.0 / norm_of_approximation) ** (1.0/ tensor.ndim)\n",
    "    for n in range(len(initial_A_ns_copy)):\n",
    "        initial_A_ns_copy[n] = initial_A_ns_copy[n] * scaling\n",
    "    start = time.time()\n",
    "    A_ns, RE, _, _ = tensor_factorization_cp_poisson(tensor_copy, F, max_iter=max_iter, detailed=True, verbose=False, initial_A_ns=initial_A_ns_copy)\n",
    "    end = time.time()\n",
    "    return IterationResult(tl.tensor(RE), end-start, A_ns)\n",
    "factorizer_geometric_norm = Factorizer(\"Geometric step size calculation with normalization\", geometric_variable_normalized, color='blue', linestyle='dotted')\n",
    "\n",
    "# The new geometric algorithm with step size calculation and but max=1 of the tensor and the initial data\n",
    "def geometric_variable_normalize_max(tensor, F, initial_A_ns):\n",
    "    # copy tensor and initial data and rescale\n",
    "    tensor_copy = tensor / tl.max(tensor) # normalize tensor\n",
    "    initial_A_ns_copy = deepcopy(initial_A_ns)\n",
    "    scaling = (1.0 / tl.max(defactorizing_CP(initial_A_ns_copy, tensor.shape))) ** (1.0/ tensor.ndim)\n",
    "    for n in range(len(initial_A_ns_copy)):\n",
    "        initial_A_ns_copy[n] = initial_A_ns_copy[n] * scaling\n",
    "    start = time.time()\n",
    "    A_ns, RE, _, _ = tensor_factorization_cp_poisson(tensor_copy, F, max_iter=max_iter, detailed=True, verbose=False, initial_A_ns=initial_A_ns_copy)\n",
    "    end = time.time()\n",
    "    return IterationResult(tl.tensor(RE), end-start, A_ns)\n",
    "factorizer_geometric_max = Factorizer(\"Geometric step size calculation with max = 1\", geometric_variable_normalize_max, color='blue', linestyle='dashed')\n",
    "\n",
    "# The new geometric algorithm with step size calculation and but mean=1 of the tensor and the initial data\n",
    "def geometric_variable_normalize_mean(tensor, F, initial_A_ns):\n",
    "    # copy tensor and initial data and rescale\n",
    "    tensor_copy = tensor / tl.mean(tensor) # normalize tensor\n",
    "    initial_A_ns_copy = deepcopy(initial_A_ns)\n",
    "    scaling = (1.0 / tl.mean(defactorizing_CP(initial_A_ns_copy, tensor.shape))) ** (1.0/ tensor.ndim)\n",
    "    for n in range(len(initial_A_ns_copy)):\n",
    "        initial_A_ns_copy[n] = initial_A_ns_copy[n] * scaling\n",
    "    start = time.time()\n",
    "    A_ns, RE, _, _ = tensor_factorization_cp_poisson(tensor_copy, F, max_iter=max_iter, detailed=True, verbose=False, initial_A_ns=initial_A_ns_copy)\n",
    "    end = time.time()\n",
    "    return IterationResult(tl.tensor(RE), end-start, A_ns)\n",
    "factorizer_geometric_mean = Factorizer(\"Geometric step size calculation with mean = 1\", geometric_variable_normalize_mean, color='blue', linestyle='dashdot')\n",
    "\n",
    "\n",
    "\n",
    "# default geometric algorithm with fixed step size. Use normalize the mean of the tensor to get some form of normalization\n",
    "def geometric_fixed_step_size(tensor, F, initial_A_ns):\n",
    "    # copy tensor and initial data and rescale\n",
    "    tensor_copy = tensor / tl.mean(tensor) # normalize tensor\n",
    "    initial_A_ns_copy = deepcopy(initial_A_ns)\n",
    "    scaling = (1.0 / tl.mean(defactorizing_CP(initial_A_ns_copy, tensor.shape))) ** (1.0/ tensor.ndim)\n",
    "    for n in range(len(initial_A_ns_copy)):\n",
    "        initial_A_ns_copy[n] = initial_A_ns_copy[n] * scaling\n",
    "    start = time.time()\n",
    "    A_ns, RE, _, _ = tensor_factorization_cp_poisson_fixed_step_size(tensor, F, max_iter=max_iter, detailed=True, verbose=False, initial_A_ns=initial_A_ns)\n",
    "    end = time.time()\n",
    "    return IterationResult(tl.tensor(RE), end-start, A_ns)\n",
    "factorizer_geometric_fixed = Factorizer(\"Geometric fixed step size\", geometric_fixed_step_size, color='green')\n",
    "\n",
    "\n",
    "# run the factorization on gpu\n",
    "tl.set_backend('pytorch')\n",
    "context = {'dtype': tl.float32,\n",
    "           'device': 'cuda'}\n",
    "#context = {}\n",
    "factorizers = [\n",
    "    factorizer_multiplicative,\n",
    "    factorizer_multiplicative_poisson,\n",
    "    factorizer_geometric,\n",
    "    factorizer_geometric_norm,\n",
    "    factorizer_geometric_max,\n",
    "    factorizer_geometric_mean,\n",
    "    factorizer_geometric_fixed,\n",
    "]\n",
    "evaluate_algorithms(factorizers, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd09cf65-1a99-47b6-bca1-96f15b5dcdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
