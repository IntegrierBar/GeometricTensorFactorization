{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50f9706-15ce-4ffe-8f37-48fa1037f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my code\n",
    "from tensorfactorization.utils import (defactorizing_CP, create_initial_data, random_cp_with_noise)\n",
    "from tensorfactorization.multiplicative import (tensor_factorization_cp_multiplicative, tensor_factorization_cp_multiplicative_poisson)\n",
    "from tensorfactorization.poisson import (BacktrackingWarning, tensor_factorization_cp_poisson, tensor_factorization_cp_poisson_fixed_step_size)\n",
    "\n",
    "from toolkit.constants import (\n",
    "    folder, data_folder, \n",
    "    error_label, iteration_label, tensor_dimension_label, time_label, \n",
    "    xscale_convergence_data, xscale_convergence, yscale_convergence\n",
    ")\n",
    "\n",
    "#%matplotlib widget\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # use pickle to save results to disk\n",
    "import warnings\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2272785-d237-441d-9086-4a5d9541ac5e",
   "metadata": {},
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ff1ba-58a9-4722-b461-df4d1744a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying do plot many stuff things, you know...\n",
    "# TODO make this use GPU! For some reason this is super slow on GPU even though it should be very fast?\n",
    "#tl.set_backend('pytorch')\n",
    "#context = {'dtype': tl.float32,\n",
    "#           'device': 'cuda'}\n",
    "tl.set_backend('numpy')\n",
    "context = {}\n",
    "\n",
    "dimensions = []\n",
    "# add large tensors\n",
    "for _ in range(50):\n",
    "    ndim = random.randint(3, 5)\n",
    "    dimension = []\n",
    "\n",
    "    max_dimension = 300*300*2\n",
    "    # TODO make tensor generation smarter so that we dont generate massive ones!\n",
    "    for n in range(ndim):\n",
    "        next_dimension = random.randint(3, max( min( int(max_dimension / 3**(ndim-n -1)), 200) , 3 ) )\n",
    "        dimension.append(next_dimension)\n",
    "        max_dimension /= next_dimension\n",
    "        \n",
    "    dimensions.append(dimension)\n",
    "\n",
    "# add small tensors\n",
    "for _ in range(100):\n",
    "    ndim = random.randint(3, 5)\n",
    "    dimension = []\n",
    "\n",
    "    for _ in range(ndim):\n",
    "        next_dimension = random.randint(3, 12 )\n",
    "        dimension.append(next_dimension)\n",
    "        \n",
    "    dimensions.append(dimension)\n",
    "\n",
    "# let us also test different sigma values\n",
    "alpha = 0.5\n",
    "beta = 0.9\n",
    "sigmas = [0.5, 0.1, 0.001]\n",
    "\n",
    "points_for_sigma = {}\n",
    "\n",
    "\n",
    "for sigma in sigmas:\n",
    "    print(\" \\n \\n Sigma = \" + str(sigma))\n",
    "    all_points = [] # list containing all points\n",
    "    \n",
    "    # big tensors only for now\n",
    "    for dimension in dimensions:\n",
    "        print(\"Dimension of new tensor: \" + str(dimension))\n",
    "        \n",
    "        F = random.randint(2, 5) # get random order between 2 and 5\n",
    "        max_iter = random.randint(6, 10) # get a random iteration between 5 and 10 \n",
    "        scaling = random.uniform(0.1, 100.0) # get a random norm for our tensor\n",
    "        \n",
    "        data_of_tensor = []\n",
    "        \n",
    "        tensor = random_cp_with_noise(dimension, F, noise_scaling=0.0, context=context) # make it have no noise\n",
    "        tensor = tensor * scaling\n",
    "        norm_of_tensor = tl.norm(tensor)\n",
    "\n",
    "        \n",
    "        print(\"doing \" + str(max_iter) + \" iteration steps, with scaling: \" +str(scaling)+\" and norm: \" + str(norm_of_tensor))\n",
    "\n",
    "        # creating initial data\n",
    "        initial_A_ns = create_initial_data(tensor, F)\n",
    "        #norm_approx = tl.norm( defactorizing_CP(initial_A_ns, tensor.shape) )\n",
    "        #scaling = (norm_of_tensor / norm_approx) ** (1.0/ tensor.ndim)\n",
    "        #for n in range(len(initial_A_ns)):\n",
    "        #    initial_A_ns[n] = initial_A_ns[n] * scaling\n",
    "        backtracking_failed = False\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            # ignore runtimewarnings as they come from stuff that doesnt matter\n",
    "            warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "            # userwarnings are my warning that backtracking failed\n",
    "            warnings.simplefilter(\"always\", BacktrackingWarning)\n",
    "            \n",
    "            A_ns, _, _, step_size_modfiers = tensor_factorization_cp_poisson(tensor, F, max_iter=max_iter, detailed=True, verbose=False, sigma=sigma, beta=beta, initial_A_ns=initial_A_ns)\n",
    "            print(\"done with factorization\")\n",
    "            \n",
    "            if w:\n",
    "                print(\"Warnings were issued during the function call, skipping tensor\")\n",
    "                if issubclass(warning.category, BacktrackingWarning):\n",
    "                    print(f\"Caught UserWarning: {warning.message}\")\n",
    "                    special_warning_issued = True\n",
    "                else:\n",
    "                    # Optionally store or print other captured warnings if you want to see what was ignored\n",
    "                    print(f\"Caught other warning (ignored): {warning.message} ({warning.category.__name__})\")\n",
    "\n",
    "        if backtracking_failed:\n",
    "            continue\n",
    "            \n",
    "        for k in range(2): # always use the 2 last iterations to get bit more data points for free\n",
    "            for n in range(tensor.ndim):\n",
    "                khatr_rao_product = tl.tenalg.khatri_rao(A_ns, skip_matrix=n)\n",
    "                data_of_tensor.append( {\n",
    "                    \"contraction\" : khatr_rao_product.shape[0], \n",
    "                    \"norm\" : norm_of_tensor, \n",
    "                    \"max\" : tl.max(tensor),\n",
    "                    \"min\" : tl.min(tensor),\n",
    "                    \"mean\" : tl.mean(tensor),\n",
    "                    \"step_size\" : alpha*math.pow(beta, step_size_modfiers[n][-k]) \n",
    "                } )\n",
    "\n",
    "        # TODO: sort the points by contraction lenght so that plot looks better\n",
    "        data_of_tensor = sorted(data_of_tensor, key=lambda x : x[\"contraction\"])\n",
    "        all_points.extend(data_of_tensor) # add the points from this tensor to the list of all points\n",
    "        contraction_lenghts = [e[\"contraction\"] for e in data_of_tensor]\n",
    "        step_sizes = [e[\"step_size\"] for e in data_of_tensor]\n",
    "        plt.plot(contraction_lenghts, step_sizes)\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.title(\"lines Sigma = \" + str(sigma))\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    # this time do the log ourselfs\n",
    "    contraction_lenghts = [math.log(e[\"contraction\"]) for e in all_points]\n",
    "    norms = [e[\"norm\"] for e in all_points]\n",
    "    step_sizes = [math.log(e[\"step_size\"]) for e in all_points]\n",
    "    \n",
    "    ax.scatter(contraction_lenghts, norms, step_sizes)\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.set_yscale('log')\n",
    "\n",
    "    ax.set_xlabel('contraction length')\n",
    "    ax.set_ylabel('norm of tensor')\n",
    "    ax.set_zlabel('step size')\n",
    "    ax.set_title(\"Sigma = \" + str(sigma))\n",
    "    plt.show()\n",
    "\n",
    "    points_for_sigma[sigma] = deepcopy(all_points)\n",
    "\n",
    "try:\n",
    "    pickle.dump( points_for_sigma, open(data_folder+'optimal_stepsize.pickle', 'wb') )\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7806dc-89fb-4980-8c30-d31add344d2f",
   "metadata": {},
   "source": [
    "# Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096947c-7949-4c53-b282-53e3c021ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_plane(points):\n",
    "    \"\"\"\n",
    "    Fits the best 2D polynomial (plane) of the form z = ax + by + c to a set of 3D points.\n",
    "    \n",
    "    Args:\n",
    "    points: A list or numpy array of 3D points, where each point is represented as [x, y, z].\n",
    "    \n",
    "    Returns:\n",
    "    A tuple (a, b, c) representing the coefficients of the fitted plane.\n",
    "    Returns None if there are fewer than 3 points.\n",
    "    \"\"\"\n",
    "    points = np.array(points)\n",
    "    if points.shape[0] < 3:\n",
    "        print(\"Error: Need at least 3 points to fit a plane.\")\n",
    "        return None\n",
    "    \n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    z = points[:, 2]\n",
    "    \n",
    "    # Construct the matrix A and vector b for the least squares fit\n",
    "    # The equation is z = a*x + b*y + c, which can be written as:\n",
    "    # [x1 y1 1] [a]   [z1]\n",
    "    # [x2 y2 1] [b] = [z2]\n",
    "    # ...       [c]   [...]\n",
    "    A = np.vstack([x, y, np.ones(len(x))]).T\n",
    "    b = z\n",
    "    \n",
    "    # Solve the least squares problem using numpy.linalg.lstsq\n",
    "    coefficients, residuals, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
    "    print(\"residual was \" + str(residuals))\n",
    "    \n",
    "    # The coefficients are in the order [a, b, c]\n",
    "    a, b, c = coefficients\n",
    "    \n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dea0de-c5c1-48c6-979d-090c5e18a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(data_folder+\"optimal_stepsize.pickle\",'rb')\n",
    "points_for_sigma = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "# iterate over all sigmas and print and plot the data\n",
    "for sigma, all_points in points_for_sigma.items():\n",
    "    print(\" \\n \\n Sigma = \" + str(sigma))\n",
    "    \n",
    "    contraction_lenghts = [math.log(e[\"contraction\"]) for e in all_points]\n",
    "    scaling_types = {\n",
    "        \"norm\" : [e[\"norm\"] for e in all_points],\n",
    "        \"max\" : [e[\"max\"] for e in all_points],\n",
    "        \"min\" : [e[\"min\"] for e in all_points],\n",
    "        \"mean\" : [e[\"mean\"] for e in all_points],\n",
    "    }\n",
    "    step_sizes = [math.log(e[\"step_size\"]) for e in all_points]\n",
    "\n",
    "    for name, data in scaling_types.items():\n",
    "        print(\"Now testing \" + name)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        ax.scatter(contraction_lenghts, data, step_sizes)\n",
    "        #ax.set_xscale('log')\n",
    "        #ax.set_yscale('log')\n",
    "    \n",
    "        ax.set_xlabel('contraction length')\n",
    "        ax.set_ylabel(name+' of tensor')\n",
    "        ax.set_zlabel('step size')\n",
    "        ax.set_title(name+\" and sigma = \" + str(sigma))\n",
    "        #plt.show()\n",
    "    \n",
    "        # let us now find the best 1d line through these points in loglog\n",
    "        points = [(math.log(p[\"contraction\"]), p[name], math.log(p[\"step_size\"])) for p in all_points]\n",
    "        coefficients = fit_plane(points)\n",
    "        print(coefficients)\n",
    "        # recalculate to exponential formula\n",
    "        print(\"so our formula is: step size = \"+str(math.pow(10, coefficients[2]))+\" * length^(\"+str(coefficients[0])+\") * e^(\"+str(coefficients[1])+\" \"+name+\")\")\n",
    "        #p = np.poly1d(z)\n",
    "        #xp = np.linspace(min(x)-1, max(x)+1, 100)\n",
    "        \n",
    "        #_ = plt.plot(x, y, '.', xp, p(xp), '-')\n",
    "        #plt.title(\"Sigma = \" + str(sigma))\n",
    "        a, b, c = coefficients\n",
    "        xp = np.linspace(min(contraction_lenghts)-1, max(contraction_lenghts)+1, 100)\n",
    "        yp = np.linspace(min(data)-1, max(data)+1, 100)\n",
    "        X, Y = np.meshgrid(xp, yp)\n",
    "        Z = a * X + b * Y + c\n",
    "        ax.plot_surface(X, Y, Z, color='red', alpha=0.5, label='Fitted Plane')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
