{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50f9706-15ce-4ffe-8f37-48fa1037f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my code\n",
    "from tensorfactorization.utils import (defactorizing_CP, create_initial_data, random_cp_with_noise)\n",
    "from tensorfactorization.multiplicative import (tensor_factorization_cp_multiplicative, tensor_factorization_cp_multiplicative_poisson)\n",
    "from tensorfactorization.poisson import (BacktrackingWarning, tensor_factorization_cp_poisson, tensor_factorization_cp_poisson_fixed_step_size)\n",
    "from data.data_imports import (load_IL2data, load_indian_pines)#, load_kinetic, load_covid19_serology\n",
    "\n",
    "from toolkit.constants import (\n",
    "    folder, data_folder, \n",
    "    error_label, iteration_label, tensor_dimension_label, time_label, \n",
    "    xscale_convergence_data, xscale_convergence, yscale_convergence\n",
    ")\n",
    "\n",
    "#%matplotlib widget\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # use pickle to save results to disk\n",
    "import warnings\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbcff88-8c84-4cd7-8f2b-2965113cdddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=4.12\n"
     ]
    }
   ],
   "source": [
    "t = 4.1234\n",
    "print(f\"t={t:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2272785-d237-441d-9086-4a5d9541ac5e",
   "metadata": {},
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ff1ba-58a9-4722-b461-df4d1744a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying do plot many stuff things, you know...\n",
    "# TODO make this use GPU! For some reason this is super slow on GPU even though it should be very fast?\n",
    "#tl.set_backend('pytorch')\n",
    "#context = {'dtype': tl.float32,\n",
    "#           'device': 'cuda'}\n",
    "tl.set_backend('numpy')\n",
    "context = {}\n",
    "\n",
    "dimensions = []\n",
    "# add large tensors\n",
    "for _ in range(50):\n",
    "    ndim = random.randint(3, 5)\n",
    "    dimension = []\n",
    "\n",
    "    max_dimension = 300*300*2\n",
    "    # TODO make tensor generation smarter so that we dont generate massive ones!\n",
    "    for n in range(ndim):\n",
    "        next_dimension = random.randint(3, max( min( int(max_dimension / 3**(ndim-n -1)), 200) , 3 ) )\n",
    "        dimension.append(next_dimension)\n",
    "        max_dimension /= next_dimension\n",
    "        \n",
    "    dimensions.append(dimension)\n",
    "\n",
    "# add small tensors\n",
    "for _ in range(100):\n",
    "    ndim = random.randint(3, 5)\n",
    "    dimension = []\n",
    "\n",
    "    for _ in range(ndim):\n",
    "        next_dimension = random.randint(3, 12 )\n",
    "        dimension.append(next_dimension)\n",
    "        \n",
    "    dimensions.append(dimension)\n",
    "\n",
    "# let us also test different sigma values\n",
    "alpha = 0.5\n",
    "beta = 0.9\n",
    "sigmas = [0.5, 0.1, 0.001]\n",
    "\n",
    "points_for_sigma = {}\n",
    "\n",
    "\n",
    "for sigma in sigmas:\n",
    "    print(\" \\n \\n Sigma = \" + str(sigma))\n",
    "    all_points = [] # list containing all points\n",
    "    \n",
    "    # big tensors only for now\n",
    "    for dimension in dimensions:\n",
    "        print(\"Dimension of new tensor: \" + str(dimension))\n",
    "        \n",
    "        F = random.randint(2, 5) # get random order between 2 and 5\n",
    "        max_iter = random.randint(6, 10) # get a random iteration between 5 and 10 \n",
    "        scaling = random.uniform(0.1, 100.0) # get a random norm for our tensor\n",
    "        \n",
    "        data_of_tensor = []\n",
    "        \n",
    "        tensor = random_cp_with_noise(dimension, F, noise_scaling=0.0, context=context) # make it have no noise\n",
    "        tensor = tensor * scaling\n",
    "        norm_of_tensor = tl.norm(tensor)\n",
    "\n",
    "        \n",
    "        print(\"doing \" + str(max_iter) + \" iteration steps, with scaling: \" +str(scaling)+\" and norm: \" + str(norm_of_tensor))\n",
    "\n",
    "        # creating initial data\n",
    "        initial_A_ns = create_initial_data(tensor, F)\n",
    "        #norm_approx = tl.norm( defactorizing_CP(initial_A_ns, tensor.shape) )\n",
    "        #scaling = (norm_of_tensor / norm_approx) ** (1.0/ tensor.ndim)\n",
    "        #for n in range(len(initial_A_ns)):\n",
    "        #    initial_A_ns[n] = initial_A_ns[n] * scaling\n",
    "        backtracking_failed = False\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            # ignore runtimewarnings as they come from stuff that doesnt matter\n",
    "            warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "            # userwarnings are my warning that backtracking failed\n",
    "            warnings.simplefilter(\"always\", BacktrackingWarning)\n",
    "            \n",
    "            A_ns, _, _, step_size_modfiers = tensor_factorization_cp_poisson(tensor, F, max_iter=max_iter, detailed=True, verbose=False, sigma=sigma, beta=beta, initial_A_ns=initial_A_ns)\n",
    "            print(\"done with factorization\")\n",
    "            \n",
    "            if w:\n",
    "                print(\"Warnings were issued during the function call, skipping tensor\")\n",
    "                if issubclass(warning.category, BacktrackingWarning):\n",
    "                    print(f\"Caught UserWarning: {warning.message}\")\n",
    "                    special_warning_issued = True\n",
    "                else:\n",
    "                    # Optionally store or print other captured warnings if you want to see what was ignored\n",
    "                    print(f\"Caught other warning (ignored): {warning.message} ({warning.category.__name__})\")\n",
    "\n",
    "        if backtracking_failed:\n",
    "            continue\n",
    "            \n",
    "        for k in range(2): # always use the 2 last iterations to get bit more data points for free\n",
    "            for n in range(tensor.ndim):\n",
    "                khatr_rao_product = tl.tenalg.khatri_rao(A_ns, skip_matrix=n)\n",
    "                data_of_tensor.append( {\n",
    "                    \"contraction\" : khatr_rao_product.shape[0], \n",
    "                    \"norm\" : norm_of_tensor, \n",
    "                    \"max\" : tl.max(tensor),\n",
    "                    \"min\" : tl.min(tensor),\n",
    "                    \"mean\" : tl.mean(tensor),\n",
    "                    \"step_size\" : alpha*math.pow(beta, step_size_modfiers[n][-k]) \n",
    "                } )\n",
    "\n",
    "        # TODO: sort the points by contraction lenght so that plot looks better\n",
    "        data_of_tensor = sorted(data_of_tensor, key=lambda x : x[\"contraction\"])\n",
    "        all_points.extend(data_of_tensor) # add the points from this tensor to the list of all points\n",
    "        contraction_lenghts = [e[\"contraction\"] for e in data_of_tensor]\n",
    "        step_sizes = [e[\"step_size\"] for e in data_of_tensor]\n",
    "        plt.plot(contraction_lenghts, step_sizes)\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.title(\"lines Sigma = \" + str(sigma))\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    # this time do the log ourselfs\n",
    "    contraction_lenghts = [math.log(e[\"contraction\"]) for e in all_points]\n",
    "    norms = [e[\"norm\"] for e in all_points]\n",
    "    step_sizes = [math.log(e[\"step_size\"]) for e in all_points]\n",
    "    \n",
    "    ax.scatter(contraction_lenghts, norms, step_sizes)\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.set_yscale('log')\n",
    "\n",
    "    ax.set_xlabel('contraction length')\n",
    "    ax.set_ylabel('norm of tensor')\n",
    "    ax.set_zlabel('step size')\n",
    "    ax.set_title(\"Sigma = \" + str(sigma))\n",
    "    plt.show()\n",
    "\n",
    "    points_for_sigma[sigma] = deepcopy(all_points)\n",
    "\n",
    "try:\n",
    "    pickle.dump( points_for_sigma, open(data_folder+'optimal_stepsize.pickle', 'wb') )\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7806dc-89fb-4980-8c30-d31add344d2f",
   "metadata": {},
   "source": [
    "# Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096947c-7949-4c53-b282-53e3c021ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_plane(points):\n",
    "    \"\"\"\n",
    "    Fits the best 2D polynomial (plane) of the form z = ax + by + c to a set of 3D points.\n",
    "    \n",
    "    Args:\n",
    "    points: A list or numpy array of 3D points, where each point is represented as [x, y, z].\n",
    "    \n",
    "    Returns:\n",
    "    A tuple (a, b, c) representing the coefficients of the fitted plane.\n",
    "    Returns None if there are fewer than 3 points.\n",
    "    \"\"\"\n",
    "    points = np.array(points)\n",
    "    if points.shape[0] < 3:\n",
    "        print(\"Error: Need at least 3 points to fit a plane.\")\n",
    "        return None\n",
    "    \n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    z = points[:, 2]\n",
    "    \n",
    "    # Construct the matrix A and vector b for the least squares fit\n",
    "    # The equation is z = a*x + b*y + c, which can be written as:\n",
    "    # [x1 y1 1] [a]   [z1]\n",
    "    # [x2 y2 1] [b] = [z2]\n",
    "    # ...       [c]   [...]\n",
    "    A = np.vstack([x, y, np.ones(len(x))]).T\n",
    "    b = z\n",
    "    \n",
    "    # Solve the least squares problem using numpy.linalg.lstsq\n",
    "    coefficients, residuals, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
    "    print(\"residual was \" + str(residuals))\n",
    "    \n",
    "    # The coefficients are in the order [a, b, c]\n",
    "    a, b, c = coefficients\n",
    "    \n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dea0de-c5c1-48c6-979d-090c5e18a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(data_folder+\"optimal_stepsize.pickle\",'rb')\n",
    "points_for_sigma = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "# iterate over all sigmas and print and plot the data\n",
    "for sigma, all_points in points_for_sigma.items():\n",
    "    print(\" \\n \\n Sigma = \" + str(sigma))\n",
    "    \n",
    "    contraction_lenghts = [math.log(e[\"contraction\"]) for e in all_points]\n",
    "    scaling_types = {\n",
    "        \"norm\" : [e[\"norm\"] for e in all_points],\n",
    "        \"max\" : [e[\"max\"] for e in all_points],\n",
    "        \"min\" : [e[\"min\"] for e in all_points],\n",
    "        \"mean\" : [e[\"mean\"] for e in all_points],\n",
    "    }\n",
    "    step_sizes = [math.log(e[\"step_size\"]) for e in all_points]\n",
    "\n",
    "    for name, data in scaling_types.items():\n",
    "        print(\"Now testing \" + name)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        ax.scatter(contraction_lenghts, data, step_sizes)\n",
    "        #ax.set_xscale('log')\n",
    "        #ax.set_yscale('log')\n",
    "    \n",
    "        ax.set_xlabel('contraction length')\n",
    "        ax.set_ylabel(name+' of tensor')\n",
    "        ax.set_zlabel('step size')\n",
    "        ax.set_title(name+\" and sigma = \" + str(sigma))\n",
    "        #plt.show()\n",
    "    \n",
    "        # let us now find the best 1d line through these points in loglog\n",
    "        points = [(math.log(p[\"contraction\"]), p[name], math.log(p[\"step_size\"])) for p in all_points]\n",
    "        coefficients = fit_plane(points)\n",
    "        print(coefficients)\n",
    "        # recalculate to exponential formula\n",
    "        print(\"so our formula is: step size = \"+str(math.pow(10, coefficients[2]))+\" * length^(\"+str(coefficients[0])+\") * e^(\"+str(coefficients[1])+\" \"+name+\")\")\n",
    "        #p = np.poly1d(z)\n",
    "        #xp = np.linspace(min(x)-1, max(x)+1, 100)\n",
    "        \n",
    "        #_ = plt.plot(x, y, '.', xp, p(xp), '-')\n",
    "        #plt.title(\"Sigma = \" + str(sigma))\n",
    "        a, b, c = coefficients\n",
    "        xp = np.linspace(min(contraction_lenghts)-1, max(contraction_lenghts)+1, 100)\n",
    "        yp = np.linspace(min(data)-1, max(data)+1, 100)\n",
    "        X, Y = np.meshgrid(xp, yp)\n",
    "        Z = a * X + b * Y + c\n",
    "        ax.plot_surface(X, Y, Z, color='red', alpha=0.5, label='Fitted Plane')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d13e3-0f4c-41c8-8986-018838da2bd0",
   "metadata": {},
   "source": [
    "# Testing on India Pines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568f956d-7837-4fdd-a455-997ca05214be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on indian pines data:\n",
      "Tensor is of shape: torch.Size([145, 145, 200]) with min: tensor(95500., device='cuda:0'), max: tensor(960400., device='cuda:0'), average: tensor(265238.9375, device='cuda:0')\n",
      "Current index: 0\n",
      "Initial m = 17\n",
      "Biggest element in -gradient: tensor(1.4619e+08, device='cuda:0')\n",
      "smallest element in -gradient: tensor(-21132168., device='cuda:0')\n",
      "Time from start to calculate gradients and first next iterate: 0.10106086730957031\n",
      "Time from start until end of step size calculation: 0.23111867904663086\n",
      "Step Size: 1.4901161193847656e-08\n",
      "m: 25\n",
      "Step size * biggest element: tensor(2.1784, device='cuda:0')\n",
      "biggest element in A_n: tensor(82.2256, device='cuda:0')\n",
      "smallest element in A_n: tensor(0.3250, device='cuda:0')\n",
      "Shape of approximated_X_unfolded_n: torch.Size([145, 29000])\n",
      "Shape of khatri Rao product: torch.Size([29000, 4])\n",
      "Calculculation time: 0.23611855506896973\n",
      "New objective function value: tensor(-1.2641e+13, device='cuda:0')\n",
      "function_value_at_iteration = tensor(-1.2577e+13, device='cuda:0')\n",
      "norm_of_rg = tensor(6.9940e+18, device='cuda:0')\n",
      "biggest Element of X/M = tensor(229.2658, device='cuda:0')\n",
      "\n",
      "Printing additional tensor information\n",
      "TENSOR: smallest: tensor(95500., device='cuda:0'), biggest: tensor(960400., device='cuda:0'), average: tensor(265238.9375, device='cuda:0')\n",
      "GRADIENT: smallest: tensor(-1.4619e+08, device='cuda:0'), biggest: tensor(21132168., device='cuda:0'), average: tensor(-10210754., device='cuda:0')\n",
      "NEXT ITERATE: smallest: tensor(0.4134, device='cuda:0'), biggest: tensor(103.2652, device='cuda:0'), average: tensor(43.1334, device='cuda:0')\n",
      "KHATRI RAO PRODUCT: smallest: tensor(0.0768, device='cuda:0'), biggest: tensor(6734.6499, device='cuda:0'), average: tensor(1603.3766, device='cuda:0')\n",
      "APPROXIMATED X: smallest: tensor(1728.5616, device='cuda:0'), biggest: tensor(1315043.5000, device='cuda:0'), average: tensor(265864.9375, device='cuda:0')\n",
      "A_ns[0]: smallest: tensor(0.4134, device='cuda:0'), biggest: tensor(103.2652, device='cuda:0'), average: tensor(43.1334, device='cuda:0')\n",
      "A_ns[1]: smallest: tensor(0.1532, device='cuda:0'), biggest: tensor(81.9445, device='cuda:0'), average: tensor(40.8185, device='cuda:0')\n",
      "A_ns[2]: smallest: tensor(0.4171, device='cuda:0'), biggest: tensor(82.1855, device='cuda:0'), average: tensor(39.3096, device='cuda:0')\n",
      "\n",
      "\n",
      "Current index: 1\n",
      "Initial m = 18\n",
      "Biggest element in -gradient: tensor(1.8119e+08, device='cuda:0')\n",
      "smallest element in -gradient: tensor(-22938860., device='cuda:0')\n",
      "Time from start to calculate gradients and first next iterate: 0.006000041961669922\n",
      "Time from start until end of step size calculation: 0.006999969482421875\n",
      "Step Size: 4.76837158203125e-07\n",
      "m: 20\n",
      "Step size * biggest element: tensor(86.3965, device='cuda:0')\n",
      "biggest element in A_n: tensor(81.9445, device='cuda:0')\n",
      "smallest element in A_n: tensor(0.1532, device='cuda:0')\n",
      "Shape of approximated_X_unfolded_n: torch.Size([145, 29000])\n",
      "Shape of khatri Rao product: torch.Size([29000, 4])\n",
      "Calculculation time: 0.009000301361083984\n",
      "New objective function value: tensor(nan, device='cuda:0')\n",
      "function_value_at_iteration = tensor(-1.2641e+13, device='cuda:0')\n",
      "norm_of_rg = tensor(6.8757e+18, device='cuda:0')\n",
      "biggest Element of X/M = tensor(97.3243, device='cuda:0')\n",
      "\n",
      "Printing additional tensor information\n",
      "TENSOR: smallest: tensor(95500., device='cuda:0'), biggest: tensor(960400., device='cuda:0'), average: tensor(265238.9375, device='cuda:0')\n",
      "GRADIENT: smallest: tensor(-1.8119e+08, device='cuda:0'), biggest: tensor(22938860., device='cuda:0'), average: tensor(-7750317., device='cuda:0')\n",
      "NEXT ITERATE: smallest: tensor(0.0014, device='cuda:0'), biggest: tensor(6.1356e+37, device='cuda:0'), average: tensor(1.2202e+35, device='cuda:0')\n",
      "KHATRI RAO PRODUCT: smallest: tensor(0.4642, device='cuda:0'), biggest: tensor(8161.4043, device='cuda:0'), average: tensor(1694.2848, device='cuda:0')\n",
      "APPROXIMATED X: smallest: tensor(4676.1182, device='cuda:0'), biggest: tensor(1134979.5000, device='cuda:0'), average: tensor(276568.8125, device='cuda:0')\n",
      "A_ns[0]: smallest: tensor(0.4134, device='cuda:0'), biggest: tensor(103.2652, device='cuda:0'), average: tensor(43.1334, device='cuda:0')\n",
      "A_ns[1]: smallest: tensor(0.0014, device='cuda:0'), biggest: tensor(6.1356e+37, device='cuda:0'), average: tensor(1.2202e+35, device='cuda:0')\n",
      "A_ns[2]: smallest: tensor(0.4171, device='cuda:0'), biggest: tensor(82.1855, device='cuda:0'), average: tensor(39.3096, device='cuda:0')\n",
      "\n",
      "\n",
      "Current index: 2\n",
      "Initial m = 0\n",
      "Biggest element in -gradient: tensor(-2.5420e+32, device='cuda:0')\n",
      "smallest element in -gradient: tensor(-inf, device='cuda:0')\n",
      "Time from start to calculate gradients and first next iterate: 0.003000020980834961\n",
      "Time from start until end of step size calculation: 0.00500035285949707\n",
      "Step Size: 0.5\n",
      "m: 0\n",
      "Step size * biggest element: tensor(-1.2710e+32, device='cuda:0')\n",
      "biggest element in A_n: tensor(82.1855, device='cuda:0')\n",
      "smallest element in A_n: tensor(0.4171, device='cuda:0')\n",
      "Shape of approximated_X_unfolded_n: torch.Size([200, 21025])\n",
      "Shape of khatri Rao product: torch.Size([21025, 4])\n",
      "Calculculation time: 0.007000446319580078\n",
      "New objective function value: tensor(nan, device='cuda:0')\n",
      "function_value_at_iteration = tensor(nan, device='cuda:0')\n",
      "norm_of_rg = tensor(inf, device='cuda:0')\n",
      "biggest Element of X/M = tensor(246767.7344, device='cuda:0')\n",
      "\n",
      "Printing additional tensor information\n",
      "TENSOR: smallest: tensor(95500., device='cuda:0'), biggest: tensor(960400., device='cuda:0'), average: tensor(265238.9375, device='cuda:0')\n",
      "GRADIENT: smallest: tensor(2.5420e+32, device='cuda:0'), biggest: tensor(inf, device='cuda:0'), average: tensor(inf, device='cuda:0')\n",
      "NEXT ITERATE: smallest: tensor(0., device='cuda:0'), biggest: tensor(0., device='cuda:0'), average: tensor(0., device='cuda:0')\n",
      "KHATRI RAO PRODUCT: smallest: tensor(0.0012, device='cuda:0'), biggest: tensor(inf, device='cuda:0'), average: tensor(inf, device='cuda:0')\n",
      "APPROXIMATED X: smallest: tensor(1.8139, device='cuda:0'), biggest: tensor(inf, device='cuda:0'), average: tensor(inf, device='cuda:0')\n",
      "A_ns[0]: smallest: tensor(0.4134, device='cuda:0'), biggest: tensor(103.2652, device='cuda:0'), average: tensor(43.1334, device='cuda:0')\n",
      "A_ns[1]: smallest: tensor(0.0014, device='cuda:0'), biggest: tensor(6.1356e+37, device='cuda:0'), average: tensor(1.2202e+35, device='cuda:0')\n",
      "A_ns[2]: smallest: tensor(0., device='cuda:0'), biggest: tensor(0., device='cuda:0'), average: tensor(0., device='cuda:0')\n",
      "\n",
      "\n",
      "current apporximation error is: tensor(1., device='cuda:0')\n",
      "Current index: 0\n",
      "Initial m = 17\n",
      "Biggest element in -gradient: tensor(-0., device='cuda:0')\n",
      "smallest element in -gradient: tensor(-0., device='cuda:0')\n",
      "Time from start to calculate gradients and first next iterate: 0.0019998550415039062\n",
      "#### PRINTING ADDITIONAL INFORMATION ####\n",
      "Current iteration: 1\n",
      "Current index: 0\n",
      "Step Size: 2.3738919364399497e-66\n",
      "m: 217\n",
      "Step size * biggest element of negative gradient: tensor(-0., device='cuda:0')\n",
      "biggest element in A_n: tensor(103.2652, device='cuda:0')\n",
      "smallest element in A_n: tensor(0.4134, device='cuda:0')\n",
      "Shape of approximated_X_unfolded_n: torch.Size([145, 29000])\n",
      "Shape of khatri Rao product: torch.Size([29000, 4])\n",
      "\n",
      "Poisson error of current iteration: tensor(1.7781e+13, device='cuda:0')\n",
      "norm of Riemannian Gradient: tensor(0., device='cuda:0')\n",
      "poisson error of next iteration: tensor(inf, device='cuda:0')\n",
      "\n",
      "Printing additional tensor information\n",
      "TENSOR: smallest: tensor(95500., device='cuda:0'), biggest: tensor(960400., device='cuda:0'), average: tensor(265238.9375, device='cuda:0')\n",
      "GRADIENT: smallest: tensor(0., device='cuda:0'), biggest: tensor(0., device='cuda:0'), average: tensor(0., device='cuda:0')\n",
      "NEXT ITERATE: smallest: tensor(0.4134, device='cuda:0'), biggest: tensor(103.2652, device='cuda:0'), average: tensor(43.1334, device='cuda:0')\n",
      "KHATRI RAO PRODUCT: smallest: tensor(0., device='cuda:0'), biggest: tensor(0., device='cuda:0'), average: tensor(0., device='cuda:0')\n",
      "APPROXIMATED X: smallest: tensor(1.1921e-07, device='cuda:0'), biggest: tensor(1.1921e-07, device='cuda:0'), average: tensor(1.1921e-07, device='cuda:0')\n",
      "A_ns[0]: smallest: tensor(0.4134, device='cuda:0'), biggest: tensor(103.2652, device='cuda:0'), average: tensor(43.1334, device='cuda:0')\n",
      "A_ns[1]: smallest: tensor(0.0014, device='cuda:0'), biggest: tensor(6.1356e+37, device='cuda:0'), average: tensor(1.2202e+35, device='cuda:0')\n",
      "A_ns[2]: smallest: tensor(0., device='cuda:0'), biggest: tensor(0., device='cuda:0'), average: tensor(0., device='cuda:0')\n",
      "\n",
      "\n",
      "Current index: 1\n",
      "Initial m = 14\n",
      "Biggest element in -gradient: tensor(-0., device='cuda:0')\n",
      "smallest element in -gradient: tensor(-0., device='cuda:0')\n",
      "Time from start to calculate gradients and first next iterate: 0.002999544143676758\n",
      "#### PRINTING ADDITIONAL INFORMATION ####\n",
      "Current iteration: 1\n",
      "Current index: 1\n",
      "Step Size: 1.8991135491519597e-65\n",
      "m: 214\n",
      "Step size * biggest element of negative gradient: tensor(-0., device='cuda:0')\n",
      "biggest element in A_n: tensor(6.1356e+37, device='cuda:0')\n",
      "smallest element in A_n: tensor(0.0014, device='cuda:0')\n",
      "Shape of approximated_X_unfolded_n: torch.Size([145, 29000])\n",
      "Shape of khatri Rao product: torch.Size([29000, 4])\n",
      "\n",
      "Poisson error of current iteration: tensor(1.7781e+13, device='cuda:0')\n",
      "norm of Riemannian Gradient: tensor(0., device='cuda:0')\n",
      "poisson error of next iteration: tensor(inf, device='cuda:0')\n",
      "\n",
      "Printing additional tensor information\n",
      "TENSOR: smallest: tensor(95500., device='cuda:0'), biggest: tensor(960400., device='cuda:0'), average: tensor(265238.9375, device='cuda:0')\n",
      "GRADIENT: smallest: tensor(0., device='cuda:0'), biggest: tensor(0., device='cuda:0'), average: tensor(0., device='cuda:0')\n",
      "NEXT ITERATE: smallest: tensor(0.0014, device='cuda:0'), biggest: tensor(6.1356e+37, device='cuda:0'), average: tensor(1.2202e+35, device='cuda:0')\n",
      "KHATRI RAO PRODUCT: smallest: tensor(0., device='cuda:0'), biggest: tensor(0., device='cuda:0'), average: tensor(0., device='cuda:0')\n",
      "APPROXIMATED X: smallest: tensor(1.1921e-07, device='cuda:0'), biggest: tensor(1.1921e-07, device='cuda:0'), average: tensor(1.1921e-07, device='cuda:0')\n",
      "A_ns[0]: smallest: tensor(0.4134, device='cuda:0'), biggest: tensor(103.2652, device='cuda:0'), average: tensor(43.1334, device='cuda:0')\n",
      "A_ns[1]: smallest: tensor(0.0014, device='cuda:0'), biggest: tensor(6.1356e+37, device='cuda:0'), average: tensor(1.2202e+35, device='cuda:0')\n",
      "A_ns[2]: smallest: tensor(0., device='cuda:0'), biggest: tensor(0., device='cuda:0'), average: tensor(0., device='cuda:0')\n",
      "\n",
      "\n",
      "Current index: 2\n",
      "Initial m = 0\n",
      "Biggest element in -gradient: tensor(nan, device='cuda:0')\n",
      "smallest element in -gradient: tensor(nan, device='cuda:0')\n",
      "Time from start to calculate gradients and first next iterate: 0.003000020980834961\n",
      "#### PRINTING ADDITIONAL INFORMATION ####\n",
      "Current iteration: 1\n",
      "Current index: 2\n",
      "Step Size: 3.111507638930571e-61\n",
      "m: 200\n",
      "Step size * biggest element of negative gradient: tensor(nan, device='cuda:0')\n",
      "biggest element in A_n: tensor(0., device='cuda:0')\n",
      "smallest element in A_n: tensor(0., device='cuda:0')\n",
      "Shape of approximated_X_unfolded_n: torch.Size([200, 21025])\n",
      "Shape of khatri Rao product: torch.Size([21025, 4])\n",
      "\n",
      "Poisson error of current iteration: tensor(nan, device='cuda:0')\n",
      "norm of Riemannian Gradient: tensor(nan, device='cuda:0')\n",
      "poisson error of next iteration: tensor(nan, device='cuda:0')\n",
      "\n",
      "Printing additional tensor information\n",
      "TENSOR: smallest: tensor(95500., device='cuda:0'), biggest: tensor(960400., device='cuda:0'), average: tensor(265238.9375, device='cuda:0')\n",
      "GRADIENT: smallest: tensor(nan, device='cuda:0'), biggest: tensor(nan, device='cuda:0'), average: tensor(nan, device='cuda:0')\n",
      "NEXT ITERATE: smallest: tensor(nan, device='cuda:0'), biggest: tensor(nan, device='cuda:0'), average: tensor(nan, device='cuda:0')\n",
      "KHATRI RAO PRODUCT: smallest: tensor(0.0012, device='cuda:0'), biggest: tensor(inf, device='cuda:0'), average: tensor(inf, device='cuda:0')\n",
      "APPROXIMATED X: smallest: tensor(nan, device='cuda:0'), biggest: tensor(nan, device='cuda:0'), average: tensor(nan, device='cuda:0')\n",
      "A_ns[0]: smallest: tensor(0.4134, device='cuda:0'), biggest: tensor(103.2652, device='cuda:0'), average: tensor(43.1334, device='cuda:0')\n",
      "A_ns[1]: smallest: tensor(0.0014, device='cuda:0'), biggest: tensor(6.1356e+37, device='cuda:0'), average: tensor(1.2202e+35, device='cuda:0')\n",
      "A_ns[2]: smallest: tensor(0., device='cuda:0'), biggest: tensor(0., device='cuda:0'), average: tensor(0., device='cuda:0')\n",
      "\n",
      "\n",
      "current apporximation error is: tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[ 48.3878,  16.0952,  50.0360,  46.5963],\n",
       "         [ 62.0744,  58.6326,  13.3421,  48.8358],\n",
       "         [  7.7630,  59.1335,  38.0683,  59.2756],\n",
       "         [ 31.8604,  59.4977,  41.0822,  21.9553],\n",
       "         [ 27.5717,  51.8317,  50.4974,  52.4710],\n",
       "         [ 56.8221,  35.9979,  45.3262,  38.5508],\n",
       "         [  3.0089,  79.1658,  28.2115,  49.1463],\n",
       "         [ 97.3780,  24.9865,  55.5545,  63.3517],\n",
       "         [ 60.9068,  37.1227,  55.4225,  49.7199],\n",
       "         [ 58.1500,  43.5225,  55.7218,   6.6077],\n",
       "         [ 59.5715,  58.7019,   0.4134,  66.4591],\n",
       "         [ 25.3362,  55.6126,  69.0299,   9.5530],\n",
       "         [ 59.8298,  53.7667,  45.2293,  45.3304],\n",
       "         [ 41.9231,  45.1707,   2.6310,  64.9068],\n",
       "         [ 39.6666,   1.1350,  30.7200,  92.5162],\n",
       "         [ 43.5349,  12.3999,  50.2174,  52.8042],\n",
       "         [ 41.5742,  25.8799,  37.3553,  63.0836],\n",
       "         [ 33.8232,  21.8577,  64.4714,  48.2040],\n",
       "         [ 36.5008,  10.7780,  72.4422,  51.5690],\n",
       "         [ 54.5067,  27.6191,  59.0713,  22.6815],\n",
       "         [ 59.5700,  39.0211,  47.3034,  43.8751],\n",
       "         [ 36.9578,  31.5805,  42.1015,  63.8829],\n",
       "         [ 64.0971,  32.5887,  65.5889,  17.2729],\n",
       "         [ 47.1136,  46.6871,  57.9555,  56.9553],\n",
       "         [ 51.1605,  47.9855,  46.8801,  16.8986],\n",
       "         [ 40.5326,  51.8702,  32.8608,  40.2054],\n",
       "         [ 68.9530,  14.8233,  31.3848,  48.2133],\n",
       "         [ 53.3727,  17.6507,  43.4809,  38.2101],\n",
       "         [ 20.2301,  59.3374,  44.0607,  57.7908],\n",
       "         [ 13.9377,  36.9742,  63.4337,  61.2607],\n",
       "         [ 11.9626,  42.7494,  45.4740,  71.4020],\n",
       "         [ 61.7346,  27.6388,  25.4797,  45.8051],\n",
       "         [ 26.0244,  34.7143,  63.5487,  45.3246],\n",
       "         [ 41.3691,   1.1751,  65.3782,  57.2351],\n",
       "         [  8.3734,  34.5339,  48.9115,  77.7710],\n",
       "         [ 71.4283,  53.1905,  27.0868,  12.8255],\n",
       "         [ 46.2543,  10.8065,  59.3547,  62.0446],\n",
       "         [ 41.7080,  65.9943,  14.9294,  64.5179],\n",
       "         [ 78.7910,  32.7145,  20.5293,  25.0833],\n",
       "         [ 78.9907,   1.7336,  46.0699,  29.7313],\n",
       "         [ 62.3506,  68.1377,   5.3904,  22.1349],\n",
       "         [ 40.2896,  36.4731,  40.0056,  65.0126],\n",
       "         [ 59.9417,   9.0160,  66.9935,  25.7052],\n",
       "         [ 61.7700,  39.3581,  47.1945,  54.7472],\n",
       "         [ 39.9306,  26.5836,  79.8050,  19.5297],\n",
       "         [ 45.9808,  61.2713,  11.3417,  58.4551],\n",
       "         [ 45.9228,  53.3331,  53.6244,  24.8494],\n",
       "         [ 68.8545,  53.4152,  17.4568,  42.1817],\n",
       "         [ 33.2434,  48.7003,  25.3488,  65.4585],\n",
       "         [ 30.2234,  48.1773,  62.1470,  50.7893],\n",
       "         [ 54.1714,  45.3859,  42.6816,  44.3520],\n",
       "         [ 24.0009,  36.8650,  60.7926,  56.6901],\n",
       "         [ 51.2007,  29.4999,   6.3321,  76.4167],\n",
       "         [ 97.8867,  12.2458,  17.0401,  34.8975],\n",
       "         [ 49.6609,  43.5745,  44.9561,  40.6210],\n",
       "         [ 72.6688,  41.6117,  36.0089,   9.2269],\n",
       "         [ 28.7059,  77.8015,  29.5279,  29.9504],\n",
       "         [ 34.5682,  49.2855,  27.0544,  59.4725],\n",
       "         [ 31.9816,  36.3293,  38.9422,  68.9304],\n",
       "         [ 42.2695,  40.4097,  29.0206,  57.3670],\n",
       "         [ 24.9811,  56.3864,  64.1693,  17.1994],\n",
       "         [ 77.4983,  31.7613,  24.1348,  36.0196],\n",
       "         [ 33.5132,  83.7795,  11.2533,  38.0443],\n",
       "         [ 11.6936,  64.3954,  11.6755,  79.6677],\n",
       "         [  7.5998,  71.8567,  42.9177,  54.3058],\n",
       "         [ 70.3527,  55.3082,  23.0444,  49.5737],\n",
       "         [ 55.2439,  63.0450,  44.1086,  37.8362],\n",
       "         [  8.1019,  39.7253,  46.3224,  74.7769],\n",
       "         [ 10.0370,  79.4134,  53.2398,  24.9272],\n",
       "         [ 33.7512,  83.4359,   2.3847,  41.6766],\n",
       "         [ 21.4576,  39.9683,  51.5132,  49.8235],\n",
       "         [ 23.4285,  54.4950,   8.2974,  75.6466],\n",
       "         [ 59.1485,  43.6750,  29.6340,  55.5400],\n",
       "         [ 54.8378,  51.4941,  56.6689,  18.3797],\n",
       "         [ 51.7920,  35.4895,   8.3084,  70.3106],\n",
       "         [ 27.6115,  62.9856,  55.6739,  28.6146],\n",
       "         [ 46.9283,  23.1207,  63.8748,  60.5098],\n",
       "         [ 65.6026,  56.7530,  28.3732,  30.8763],\n",
       "         [ 30.6068,  65.2248,  17.5484,  70.0222],\n",
       "         [ 38.2715,  38.5381,  42.7487,  52.7681],\n",
       "         [ 18.5285,  43.2503,  76.0076,  24.9447],\n",
       "         [ 42.2278,  18.5992,  73.6446,  31.2176],\n",
       "         [ 43.9481,  16.9493,  83.2458,  18.6841],\n",
       "         [ 58.6081,  88.1213,   4.1104,   6.2986],\n",
       "         [ 57.0609,  16.3658,  68.9558,  39.7038],\n",
       "         [ 67.7169,  23.7838,  62.5801,   7.2012],\n",
       "         [ 78.8202,  10.1406,  58.3146,  12.5804],\n",
       "         [ 56.3707,  77.5142,   2.6118,  21.5673],\n",
       "         [ 36.1250,  53.8547,  65.1141,   7.0588],\n",
       "         [ 61.0961,  61.4871,  15.1334,  46.5396],\n",
       "         [ 27.9806,  43.8928,  32.3490,  54.0263],\n",
       "         [ 30.9577,  47.0733,  68.0210,  13.0819],\n",
       "         [ 10.5132,  61.4512,  16.0405,  76.0696],\n",
       "         [ 77.8076,   8.7157,  52.4687,  18.2535],\n",
       "         [ 58.9415,  18.4717,  47.6150,  63.1484],\n",
       "         [ 30.8547,  46.1605,  47.8045,  42.8337],\n",
       "         [ 74.1633,   8.2783,  59.6049,  17.0480],\n",
       "         [ 49.8407,  70.1432,  31.8941,   7.2771],\n",
       "         [ 21.6271,  47.8438,  31.7066,  69.3085],\n",
       "         [ 24.0354,  47.5127,  43.4526,  57.0211],\n",
       "         [ 68.6130,   9.2525,  50.5838,  44.4581],\n",
       "         [ 33.6153,   1.4241,  59.9110,  65.3874],\n",
       "         [ 30.4648,  58.2525,  41.0889,  58.9727],\n",
       "         [ 30.2917,  39.0528,  65.1211,  52.4432],\n",
       "         [ 12.5157,  58.6895,  47.3566,  38.5187],\n",
       "         [ 22.6836,  40.5761,  78.5245,  20.6177],\n",
       "         [ 21.1498,  56.1607,  24.0660,  59.9713],\n",
       "         [ 52.3140,  64.9908,  53.1980,   6.7947],\n",
       "         [ 49.7133,  17.8238,  55.0021,  38.5068],\n",
       "         [ 66.0114,  43.9571,  17.1039,  96.4700],\n",
       "         [ 22.6045,  42.2224,  36.1737,  69.7978],\n",
       "         [ 38.9201,  48.3391,   8.3334,  70.8167],\n",
       "         [ 43.8764,  34.2549,  59.2789,  40.9332],\n",
       "         [ 13.0136,  69.2305,  22.3587,  65.3255],\n",
       "         [ 23.6639,   7.9657,  71.9713,  64.1184],\n",
       "         [ 66.5350,  69.6057,  16.8974,  14.9000],\n",
       "         [  8.0864,  57.2815,  70.9551,  33.5531],\n",
       "         [ 56.4725,  60.0060,  39.9296,  47.4779],\n",
       "         [ 42.9828,  46.6766,  63.7904,  26.1828],\n",
       "         [ 27.8791,  51.8135,  11.2104,  70.2531],\n",
       "         [ 31.1722,  16.3689,  38.0104,  70.2450],\n",
       "         [ 69.8303,  53.8567,  36.7760,   5.4577],\n",
       "         [ 22.2459,  39.7945,  66.6368,  42.4089],\n",
       "         [ 37.3257,  41.4230,  31.2610,  65.4723],\n",
       "         [ 25.6839,  61.3408,  58.2978,  31.0124],\n",
       "         [ 40.4256,  46.8982,  45.5872,  45.8975],\n",
       "         [ 44.5045,  54.6520,  43.6026,  34.7973],\n",
       "         [ 54.4994,  33.0549,  59.1774,  55.9398],\n",
       "         [ 12.9376,  60.7620,  70.0994,  21.8541],\n",
       "         [ 40.5684,  24.5626,   6.0185, 103.2652],\n",
       "         [ 25.4800,  12.2297,  51.4465,  69.4950],\n",
       "         [ 16.0504,  31.6417,  98.4227,  27.8850],\n",
       "         [ 61.5582,  21.6453,  18.8186,  61.0840],\n",
       "         [ 29.5713,  67.2493,  30.2878,  43.7139],\n",
       "         [ 62.6342,  17.5927,  46.1964,  25.2031],\n",
       "         [ 19.6621,  69.8470,  41.0059,  36.8050],\n",
       "         [ 66.7785,  30.1389,  46.4536,  19.1918],\n",
       "         [ 58.3730,  49.9184,  59.4337,  22.9350],\n",
       "         [ 27.7881,  45.8765,  53.1350,  44.4677],\n",
       "         [ 52.0387,  15.9809,  46.6454,  59.0621],\n",
       "         [ 37.6523,  39.0145,  49.5091,  44.7975],\n",
       "         [ 57.9266,  47.5496,   8.5834,  58.4774],\n",
       "         [ 60.2499,  62.7775,  55.5199,  11.4733],\n",
       "         [ 52.3969,  41.5843,  50.3145,  44.6620],\n",
       "         [ 61.4040,  17.5401,  64.7889,  15.6826]], device='cuda:0'),\n",
       " tensor([[1.7861e+03, 7.0756e+05, 1.3001e+06, 4.8267e+03],\n",
       "         [8.1973e-02, 1.7732e-02, 6.4533e-02, 1.4926e-01],\n",
       "         [6.4815e+03, 2.5530e+01, 5.1144e+01, 9.7978e+01],\n",
       "         [1.4042e+00, 2.0538e-01, 6.2761e+00, 2.8345e+00],\n",
       "         [9.7746e+02, 7.3397e+00, 2.7838e+00, 8.2747e+01],\n",
       "         [1.8817e+00, 1.9946e+00, 2.1883e-01, 6.5196e-01],\n",
       "         [3.1657e+00, 2.2120e-01, 5.6695e+00, 1.9228e-01],\n",
       "         [6.9333e-02, 1.3156e-01, 6.6942e-02, 4.8540e-02],\n",
       "         [9.3419e+01, 6.1201e+03, 5.6487e+03, 1.4061e+02],\n",
       "         [1.0033e+02, 1.0274e+03, 5.9182e+02, 1.1162e+01],\n",
       "         [1.8328e+03, 2.0030e+00, 3.3144e+00, 3.2996e+03],\n",
       "         [7.7282e-01, 4.4066e-01, 1.5427e-01, 1.8969e-01],\n",
       "         [7.0914e+00, 1.3339e+00, 8.1878e-01, 3.8678e-01],\n",
       "         [1.2329e+01, 1.9281e+00, 7.7199e-01, 2.2151e+00],\n",
       "         [1.6174e-01, 3.2706e-02, 8.5538e-02, 2.6572e-02],\n",
       "         [5.0799e-03, 2.5577e-03, 5.9997e-03, 5.7742e-03],\n",
       "         [1.5788e-01, 5.1998e-01, 3.8191e-02, 5.6320e-02],\n",
       "         [1.1957e+00, 6.9507e-02, 1.4883e-01, 1.7243e-01],\n",
       "         [1.9720e+05, 7.8837e+03, 1.4941e+08, 2.2300e+06],\n",
       "         [2.6129e-03, 1.4120e-03, 2.9749e-03, 2.7542e-03],\n",
       "         [1.3458e+05, 2.7679e+02, 1.2772e+03, 1.5747e+02],\n",
       "         [3.3418e+00, 5.4843e+00, 6.1990e-01, 1.7096e+00],\n",
       "         [1.9513e+02, 7.7050e+00, 4.5245e+02, 2.5777e+02],\n",
       "         [1.1229e+00, 2.4113e+00, 1.2212e+00, 1.0884e+00],\n",
       "         [3.5032e-02, 6.0370e-02, 6.5792e-02, 6.6712e-02],\n",
       "         [1.0601e+01, 1.0538e+01, 4.0266e+02, 4.6654e+00],\n",
       "         [3.5529e+04, 1.2135e+11, 2.0258e+09, 7.0816e+12],\n",
       "         [8.0390e-02, 1.7310e-02, 1.3674e-01, 9.6293e-02],\n",
       "         [1.0969e-02, 6.7348e-03, 4.6019e-03, 9.0574e-03],\n",
       "         [3.3818e+02, 4.4236e+05, 6.8621e+05, 2.3221e+04],\n",
       "         [4.1417e-02, 1.5289e-01, 4.2111e-02, 1.4375e-01],\n",
       "         [1.7297e+03, 2.3547e+01, 3.0606e+02, 3.6731e+03],\n",
       "         [1.5439e-02, 8.8449e-03, 1.2915e-02, 2.6811e-02],\n",
       "         [2.5828e+03, 1.0398e+01, 8.9012e+00, 5.1680e+03],\n",
       "         [5.1699e-01, 6.7399e-01, 1.3092e+00, 6.2621e-01],\n",
       "         [1.8684e+00, 1.7468e-01, 8.1888e+00, 2.3889e-01],\n",
       "         [1.0923e+15, 1.3994e+10, 1.4748e+13, 6.5092e+05],\n",
       "         [6.9141e+01, 9.8778e+01, 1.2118e+02, 1.5091e+01],\n",
       "         [8.6373e+00, 9.8827e+00, 5.8016e+00, 8.8536e+00],\n",
       "         [2.2364e+14, 4.1279e+18, 8.7684e+13, 1.7943e+10],\n",
       "         [6.4462e+02, 3.5036e+02, 2.0628e+05, 2.1469e+04],\n",
       "         [4.7460e+06, 9.1223e+05, 3.3618e+04, 1.0011e+05],\n",
       "         [4.9580e+04, 2.6971e+03, 7.9138e+04, 4.1314e+03],\n",
       "         [7.4527e+03, 1.9651e+08, 6.9378e+05, 9.6264e+07],\n",
       "         [5.8686e+02, 2.2466e+04, 9.0511e+04, 4.1834e+01],\n",
       "         [2.0419e+08, 3.1199e+05, 8.4331e+05, 2.2925e+05],\n",
       "         [3.7978e+00, 1.2759e+00, 3.8063e+01, 7.4808e-01],\n",
       "         [8.8832e-01, 2.9786e-01, 1.0019e+01, 1.0856e+00],\n",
       "         [2.8155e+09, 4.6424e+06, 1.2027e+04, 4.1446e+08],\n",
       "         [9.8858e+00, 2.5480e+02, 5.1513e+00, 1.2872e+01],\n",
       "         [8.5796e+29, 1.2530e+23, 9.4147e+36, 6.1356e+37],\n",
       "         [2.3154e+04, 5.2541e+06, 2.1080e+05, 5.7482e+08],\n",
       "         [5.4894e+05, 9.8643e+07, 2.3647e+07, 2.7667e+03],\n",
       "         [3.0354e-01, 3.2713e-01, 3.5806e-01, 2.1224e+00],\n",
       "         [3.9238e+00, 4.6076e+01, 1.9817e+01, 9.3818e+00],\n",
       "         [5.0536e+00, 7.5833e+01, 2.2442e+00, 1.9734e+00],\n",
       "         [6.0099e+00, 3.4585e-01, 1.6038e+01, 1.5307e+00],\n",
       "         [2.4132e+03, 8.7050e+04, 4.7187e+03, 1.8303e+02],\n",
       "         [3.6411e+02, 8.1881e+02, 1.2401e+05, 4.7465e+03],\n",
       "         [2.4523e+27, 4.1593e+28, 2.3269e+12, 9.3247e+24],\n",
       "         [1.0979e+05, 1.0390e+04, 1.0908e+02, 1.1769e+01],\n",
       "         [1.6272e+01, 4.7017e+00, 4.7083e+00, 2.1300e+00],\n",
       "         [1.5185e+02, 8.0383e+05, 2.6624e+02, 1.1599e+05],\n",
       "         [3.2500e+10, 4.3043e+08, 4.8964e+06, 1.0252e+06],\n",
       "         [1.7302e+02, 1.5961e+01, 5.9070e+02, 2.9455e+03],\n",
       "         [2.6626e+17, 1.2113e+10, 9.8114e+13, 4.1873e+16],\n",
       "         [9.9478e+01, 1.1983e+02, 2.7254e+04, 1.5958e+03],\n",
       "         [1.9751e+05, 9.1507e+04, 3.1987e+07, 1.9838e+04],\n",
       "         [4.2438e+06, 4.7688e+08, 4.0163e+07, 1.1935e+08],\n",
       "         [2.7502e+06, 6.0676e+10, 8.7304e+10, 2.5399e+04],\n",
       "         [3.3232e+20, 1.3105e+21, 2.2920e+17, 9.7067e+21],\n",
       "         [3.0607e+07, 7.0805e+06, 6.2056e+07, 2.5569e+03],\n",
       "         [9.7366e+01, 9.3571e+00, 1.8449e+00, 6.7975e-01],\n",
       "         [7.8848e-01, 1.9257e-01, 1.9617e+00, 3.1441e-01],\n",
       "         [3.3107e+03, 1.3439e+01, 1.2565e+02, 1.4560e+02],\n",
       "         [6.5467e-01, 1.0210e-01, 4.9374e-02, 6.6145e-02],\n",
       "         [5.8790e+00, 7.0695e+00, 7.0318e+00, 3.1700e+00],\n",
       "         [6.1785e+01, 7.8112e+01, 1.4269e+03, 1.2320e+01],\n",
       "         [3.2339e+03, 3.3035e+03, 2.1679e+01, 8.5255e+03],\n",
       "         [4.1017e+00, 4.4995e+01, 9.6435e+00, 9.9346e+02],\n",
       "         [4.4835e-01, 6.1322e-02, 5.0874e-02, 9.8108e-02],\n",
       "         [3.6661e+04, 2.9725e+04, 6.4029e+01, 7.0402e+03],\n",
       "         [9.7200e+12, 3.7143e+10, 8.9546e+11, 2.7812e+13],\n",
       "         [1.3161e+02, 1.1226e+01, 7.1208e+03, 2.6318e+02],\n",
       "         [1.9463e+11, 6.1516e+03, 1.4309e+10, 2.2416e+10],\n",
       "         [3.1755e-01, 2.4360e-02, 5.9847e-02, 1.1180e-01],\n",
       "         [1.0283e+01, 1.5478e+00, 1.2174e+00, 1.3265e+02],\n",
       "         [2.6826e+03, 1.4652e+02, 2.0695e+04, 7.1148e+03],\n",
       "         [3.4046e-02, 8.6330e-03, 7.8289e-03, 1.4690e-02],\n",
       "         [7.2472e+03, 1.4072e+01, 2.4464e+02, 7.3042e+02],\n",
       "         [1.1634e+05, 3.4975e+09, 3.8961e+05, 5.3256e+08],\n",
       "         [8.5399e+00, 4.5865e+02, 4.3495e+02, 1.9990e+00],\n",
       "         [2.9291e+02, 7.0446e+00, 4.3307e+01, 2.4191e+00],\n",
       "         [6.6112e+02, 3.0668e+05, 1.9896e+04, 1.2468e+03],\n",
       "         [6.2888e+11, 3.8965e+08, 3.1435e+09, 7.8885e+08],\n",
       "         [1.3816e-01, 5.4531e-02, 1.6411e+00, 1.9143e-01],\n",
       "         [8.6878e+05, 1.1589e+03, 7.7835e+01, 1.2168e+05],\n",
       "         [2.0489e+07, 8.0235e+08, 2.4324e+05, 1.4850e+07],\n",
       "         [5.7137e-03, 5.5126e-03, 3.5749e-03, 7.3623e-03],\n",
       "         [7.4893e+00, 7.3346e-01, 4.6795e-01, 1.0576e+00],\n",
       "         [1.8005e+02, 7.2274e+02, 2.4084e+03, 2.3176e+02],\n",
       "         [6.4352e+07, 4.2112e+02, 6.4060e+05, 3.9771e+05],\n",
       "         [2.8477e-02, 3.6270e-02, 3.9150e-02, 1.7738e-02],\n",
       "         [2.7285e-01, 2.6260e-02, 5.8211e-02, 2.4292e-01],\n",
       "         [5.7424e+11, 2.5317e+10, 1.2944e+09, 4.4064e+06],\n",
       "         [6.2351e-01, 3.3269e-02, 8.9425e-02, 5.5344e-02],\n",
       "         [9.6834e+01, 2.0924e+01, 9.4270e-01, 7.0240e+00],\n",
       "         [1.6185e+09, 2.4085e+10, 9.2132e+09, 7.4075e+06],\n",
       "         [1.8704e+01, 5.7484e+00, 8.9802e+00, 3.2752e+01],\n",
       "         [1.1757e+17, 8.9790e+15, 5.4829e+05, 4.7821e+16],\n",
       "         [2.7236e+00, 1.2556e+00, 5.6010e-01, 6.0292e+01],\n",
       "         [1.0028e-01, 2.1368e-02, 1.8413e-02, 1.8991e-02],\n",
       "         [1.2672e+03, 7.1374e+01, 2.7606e+02, 6.6045e+04],\n",
       "         [2.0248e+12, 4.7228e+16, 3.7182e+12, 1.2336e+13],\n",
       "         [2.7054e+01, 4.3233e+00, 1.2173e+00, 3.6528e-01],\n",
       "         [5.5396e+02, 8.3093e+05, 2.6593e+05, 3.3905e+03],\n",
       "         [5.8471e+02, 9.6835e+02, 5.2959e+00, 7.3391e+00],\n",
       "         [1.0755e+05, 4.8264e+05, 2.3737e+07, 4.1241e+07],\n",
       "         [7.8204e-01, 2.8974e+00, 3.4945e-01, 1.4310e-01],\n",
       "         [4.7871e-03, 3.8934e-03, 3.9478e-03, 7.0984e-03],\n",
       "         [3.1093e-02, 1.9225e-02, 2.1538e-01, 4.4552e-02],\n",
       "         [1.2600e+10, 4.5152e+07, 1.4829e+06, 8.9917e+04],\n",
       "         [4.9147e+01, 5.8506e+03, 1.3254e+01, 5.0930e+03],\n",
       "         [8.7503e+03, 1.1024e+03, 9.2723e+05, 4.6892e+05],\n",
       "         [9.7992e-02, 4.7180e-02, 1.4107e-01, 1.2312e+00],\n",
       "         [1.0416e+02, 5.3199e+04, 3.1950e+03, 3.5672e+02],\n",
       "         [3.1999e+05, 8.4619e+02, 3.2294e+06, 3.6759e+04],\n",
       "         [7.1339e+00, 3.9275e+02, 2.0740e+02, 1.4750e+02],\n",
       "         [5.4879e+00, 6.6143e-01, 2.5263e+00, 3.6580e-01],\n",
       "         [2.7481e+01, 1.5996e+01, 3.6723e+00, 2.0807e+00],\n",
       "         [4.6739e+01, 6.7466e+01, 1.4840e+02, 6.3865e+03],\n",
       "         [1.5708e+01, 3.1315e+01, 2.3008e+03, 1.9509e+03],\n",
       "         [5.0554e-02, 1.6760e-02, 2.1296e-02, 2.8532e-01],\n",
       "         [3.5458e-02, 3.3030e-02, 3.6256e-02, 9.1219e-02],\n",
       "         [8.3436e+14, 1.2554e+12, 9.1117e+14, 4.2480e+07],\n",
       "         [2.4842e-01, 1.3749e-01, 2.8894e-01, 1.7233e-01],\n",
       "         [4.6228e-01, 1.1075e+00, 7.5831e+00, 2.0503e-01],\n",
       "         [1.8600e+01, 1.4749e+01, 7.1930e+01, 2.5804e+01],\n",
       "         [8.4258e+00, 2.0804e+03, 5.4365e+00, 5.1293e+02],\n",
       "         [3.0474e+00, 6.3653e+00, 4.3391e+01, 4.1218e+00],\n",
       "         [9.8267e-02, 3.1679e-02, 3.1862e-02, 6.6406e-02],\n",
       "         [4.0921e+03, 5.9190e+05, 1.2438e+06, 1.1547e+03],\n",
       "         [7.6977e-03, 1.9128e-02, 5.0468e-03, 8.0478e-03],\n",
       "         [1.2476e+00, 5.1606e+00, 4.0063e+01, 1.9935e+00],\n",
       "         [5.1780e+05, 2.1346e+09, 2.2905e+10, 1.5493e+12]], device='cuda:0'),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]], device='cuda:0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.set_backend('pytorch')\n",
    "context = {'dtype': tl.float32,\n",
    "           'device': 'cuda'}\n",
    "\n",
    "print(\"\\nTesting on indian pines data:\")\n",
    "indian_pines = load_indian_pines()\n",
    "tensor = tl.tensor(indian_pines.tensor, **context)\n",
    "tensor = tensor*100.0\n",
    "#tensor = tensor / tl.max(tensor)\n",
    "print(\"Tensor is of shape: \" + str(tensor.shape)+\" with min: \"+str(tl.min(tensor))+\", max: \"+str(tl.max(tensor))+\", average: \"+str(tl.mean(tensor)))\n",
    "F = 4 # TODO find good F here\n",
    "# generate initial A_ns\n",
    "initial_A_ns = create_initial_data(tensor, F)\n",
    "\n",
    "tensor_factorization_cp_poisson(tensor,F,max_iter=3,verbose=True, initial_A_ns=initial_A_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddbc0a1-7de4-4467-9f4b-ad1e87eafa1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
