{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02619ec-3caa-4a76-b5c4-ceda773e72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my code\n",
    "from tensorfactorization.utils import (defactorizing_CP, create_initial_data, random_cp_with_noise)\n",
    "from tensorfactorization.multiplicative import (tensor_factorization_cp_multiplicative, tensor_factorization_cp_multiplicative_poisson)\n",
    "from tensorfactorization.poisson import (BacktrackingWarning, tensor_factorization_cp_poisson, tensor_factorization_cp_poisson_fixed_step_size)\n",
    "\n",
    "from toolkit.constants import (\n",
    "    picture_folder, data_folder, \n",
    "    error_label, iteration_label, tensor_dimension_label, time_label, \n",
    "    xscale_convergence_data, xscale_convergence, yscale_convergence\n",
    ")\n",
    "from toolkit.classes import (\n",
    "    IterationResult,\n",
    "    Factorizer\n",
    ")\n",
    "from toolkit.evaluate import (\n",
    "    evaluate_on_random, evaluate_on_data, evaluate_on_images, \n",
    "    plot_calculation_times_and_niter\n",
    ")\n",
    "from data.data_imports import load_indian_pines\n",
    "\n",
    "#%matplotlib widget\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # use pickle to save results to disk\n",
    "import warnings\n",
    "\n",
    "from skimage import data\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f24148f0-e233-46e6-8e67-4376bfc93e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_cp_rank(\n",
    "    tensor,\n",
    "    max_rank,\n",
    "    tolerance=1e-3,  # Threshold for \"significant drop\" in error\n",
    "    min_error_diff=None, # Alternative: minimum absolute error difference to consider significant\n",
    "    n_initializations=3, # Number of random initializations for CP-ALS\n",
    "    random_state=None,   # For reproducibility\n",
    "    plot_error=True      # Whether to plot the error curve\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds an optimal CP rank by iteratively increasing the rank and monitoring\n",
    "    the relative reconstruction error. Stops when the relative error improvement\n",
    "    falls below a specified tolerance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : tl.tensor\n",
    "        The input tensor to decompose.\n",
    "    max_rank : int\n",
    "        The maximum rank to test.\n",
    "    tolerance : float, optional\n",
    "        The relative change in error below which to stop.\n",
    "        (current_error - previous_error) / previous_error < tolerance.\n",
    "        Defaults to 1e-3 (0.1%).\n",
    "    min_error_diff : float, optional\n",
    "        An alternative or additional stopping criterion. If the absolute\n",
    "        difference in error (previous_error - current_error) falls below\n",
    "        this value, stop. Useful for very small absolute changes.\n",
    "    n_initializations : int, optional\n",
    "        Number of random initializations for CP-ALS for each rank. The best\n",
    "        (lowest error) decomposition is chosen. Defaults to 3.\n",
    "    random_state : int or None, optional\n",
    "        Seed for the random number generator for reproducibility.\n",
    "        Defaults to None (no fixed seed).\n",
    "    plot_error : bool, optional\n",
    "        If True, plots the relative reconstruction error vs. rank. Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The suggested optimal rank.\n",
    "    list\n",
    "        A list of (rank, relative_error) tuples.\n",
    "    \"\"\"\n",
    "\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    errors = []\n",
    "    best_rank = 1\n",
    "    previous_error = float('inf')\n",
    "\n",
    "    print(f\"Starting CP rank determination (max_rank={max_rank}, tolerance={tolerance})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for rank in range(1, max_rank + 1):\n",
    "        print(f\"Testing rank {rank}...\")\n",
    "        current_rank_errors = []\n",
    "        for i in range(n_initializations):\n",
    "            try:\n",
    "                # CP-ALS decomposition\n",
    "                # 'mask' is useful if you have missing values, but for this example, we assume none\n",
    "                cp_factorization, RE = tl.decomposition.non_negative_parafac(tensor, rank=rank, init='random', n_iter_max=1000, tol=1e-8, return_errors=True)\n",
    "\n",
    "                # Reconstruct the tensor\n",
    "                #reconstructed_tensor = tl.cp_to_tensor(cp_factorization)\n",
    "\n",
    "                # Calculate the relative reconstruction error\n",
    "                #error = tl.norm(tensor - reconstructed_tensor) / tl.norm(tensor)\n",
    "                current_rank_errors.append(tl.to_numpy(RE[-1]))\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Error during decomposition for rank {rank}, initialization {i}: {e}\")\n",
    "                # If an error occurs (e.g., degeneracy), skip this initialization\n",
    "                current_rank_errors.append(float('inf'))\n",
    "\n",
    "        if not current_rank_errors:\n",
    "            print(f\"  No successful initializations for rank {rank}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        # Take the minimum error across initializations for the current rank\n",
    "        current_error = min(current_rank_errors)\n",
    "        errors.append((rank, current_error))\n",
    "        print(f\"  Rank {rank} - Min Relative Error: {current_error:.6f}\")\n",
    "\n",
    "        if rank > 1:\n",
    "            # Calculate the relative improvement\n",
    "            # We want (previous_error - current_error) / previous_error\n",
    "            # If previous_error is 0 (perfect fit), this would be undefined, but unlikely with real data\n",
    "            if previous_error == 0:\n",
    "                relative_improvement = 0\n",
    "            else:\n",
    "                relative_improvement = (previous_error - current_error) / previous_error\n",
    "\n",
    "            absolute_difference = previous_error - current_error\n",
    "\n",
    "            print(f\"  Relative Improvement from Rank {rank-1} to {rank}: {relative_improvement:.6f}\")\n",
    "            print(f\"  Absolute Difference from Rank {rank-1} to {rank}: {absolute_difference:.6f}\")\n",
    "\n",
    "            # Stopping criteria\n",
    "            should_stop_relative = relative_improvement < tolerance\n",
    "            should_stop_absolute = False\n",
    "            if min_error_diff is not None:\n",
    "                should_stop_absolute = absolute_difference < min_error_diff\n",
    "\n",
    "            if should_stop_relative or should_stop_absolute:\n",
    "                print(f\"\\nStopping at Rank {rank-1}:\")\n",
    "                if should_stop_relative:\n",
    "                    print(f\"  Relative error improvement ({relative_improvement:.6f}) below tolerance ({tolerance}).\")\n",
    "                if should_stop_absolute:\n",
    "                    print(f\"  Absolute error difference ({absolute_difference:.6f}) below min_error_diff ({min_error_diff}).\")\n",
    "                best_rank = rank - 1 # The previous rank was the last \"significant\" one\n",
    "                break\n",
    "        \n",
    "        previous_error = current_error\n",
    "        best_rank = rank # Default to current rank if loop continues\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Suggested Optimal Rank: {best_rank}\")\n",
    "\n",
    "    if plot_error:\n",
    "        ranks_tested = [e[0] for e in errors]\n",
    "        error_values = [e[1] for e in errors]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(ranks_tested, error_values, marker='o', linestyle='-')\n",
    "        plt.title('Relative Reconstruction Error vs. CP Rank')\n",
    "        plt.xlabel('Rank')\n",
    "        plt.ylabel('Relative Reconstruction Error')\n",
    "        plt.xticks(ranks_tested)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        if best_rank is not None and best_rank > 0:\n",
    "            plt.axvline(x=best_rank, color='r', linestyle='--', label=f'Suggested Rank: {best_rank}')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return best_rank, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e22eb7-eac8-40a3-bab5-e127f98ae20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_rank(tensor, n_initializations=3, J_max=10, max_iter=200, algorithm=None):\n",
    "    if algorithm == None:\n",
    "        algorithm = tensor_factorization_cp_multiplicative\n",
    "    best_J = 0\n",
    "    approx_errors = [0]\n",
    "    for J in range(1,J_max+1):\n",
    "        print(J)\n",
    "        current_errors = []\n",
    "        for _ in range(n_initializations):\n",
    "            _, RE = tl.decomposition.non_negative_parafac(tensor, J, return_errors=True)\n",
    "            current_errors.append(tl.to_numpy(RE[-1]))\n",
    "        approx_errors.append(min(current_errors))\n",
    "\n",
    "        if J < 2:\n",
    "            continue\n",
    "        prev_slope = approx_errors[-2] - approx_errors[-3]\n",
    "        current_slope = approx_errors[-1] - approx_errors[-2]\n",
    "        print(current_slope)\n",
    "        #print(prev_slope)\n",
    "        if current_slope > -0.01:\n",
    "            print(f\"The correct rank is {J-1}\")\n",
    "            best_J = J-1\n",
    "            #break\n",
    "    x = range(1, len(approx_errors))\n",
    "    print(x)\n",
    "    plt.plot(x, approx_errors[1:])\n",
    "    plt.xticks(x)\n",
    "    return best_J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab1e950-dc32-43f6-8045-e5b20f1b680d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "The requested file is part of the scikit-image distribution, but requires the installation of an optional dependency, pooch. To install pooch, use your preferred python package manager. Follow installation instruction found at https://scikit-image.org/docs/stable/user_guide/install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m tensor \u001b[38;5;241m=\u001b[39m random_cp_with_noise((\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m), \u001b[38;5;241m5\u001b[39m, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#find_best_rank(tensor)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m tensor \u001b[38;5;241m=\u001b[39m tl\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlily\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcontext)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#find_best_rank(tensor, J_max=10)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m tensor \u001b[38;5;241m=\u001b[39m tl\u001b[38;5;241m.\u001b[39mtensor(load_indian_pines()\u001b[38;5;241m.\u001b[39mtensor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcontext)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensor_factorization\\lib\\site-packages\\skimage\\data\\_fetchers.py:765\u001b[0m, in \u001b[0;36mlily\u001b[1;34m()\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlily\u001b[39m():\n\u001b[0;32m    745\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Lily of the valley plant stem.\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \n\u001b[0;32m    747\u001b[0m \u001b[38;5;124;03m    This plant stem on a pre-prepared slide was imaged with confocal\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03m        Lily 2D multichannel image.\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/lily.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensor_factorization\\lib\\site-packages\\skimage\\data\\_fetchers.py:334\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(f, as_gray)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# importing io is quite slow since it scans all the backends\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# we lazy import it here\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m imread(\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m, as_gray\u001b[38;5;241m=\u001b[39mas_gray)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensor_factorization\\lib\\site-packages\\skimage\\data\\_fetchers.py:217\u001b[0m, in \u001b[0;36m_fetch\u001b[1;34m(data_filename)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _image_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     _skip_pytest_case_requiring_pooch(data_filename)\n\u001b[1;32m--> 217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe requested file is part of the scikit-image distribution, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut requires the installation of an optional dependency, pooch. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install pooch, use your preferred python package manager. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFollow installation instruction found at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://scikit-image.org/docs/stable/user_guide/install.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Download the data with pooch which caches it automatically\u001b[39;00m\n\u001b[0;32m    225\u001b[0m _ensure_cache_dir(target_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: The requested file is part of the scikit-image distribution, but requires the installation of an optional dependency, pooch. To install pooch, use your preferred python package manager. Follow installation instruction found at https://scikit-image.org/docs/stable/user_guide/install.html"
     ]
    }
   ],
   "source": [
    "# run the factorization on gpu\n",
    "tl.set_backend('pytorch')\n",
    "context = {'dtype': tl.float32,\n",
    "           'device': 'cuda'}\n",
    "tensor = random_cp_with_noise((10,10,10), 5, context=context)\n",
    "#find_best_rank(tensor)\n",
    "\n",
    "tensor = tl.tensor(data.retina(), **context)\n",
    "#find_best_rank(tensor, J_max=10)\n",
    "\n",
    "tensor = tl.tensor(load_indian_pines().tensor, **context)\n",
    "#find_best_rank(tensor)\n",
    "\n",
    "# TODO this one does not seme to work here?\n",
    "tensor = tl.tensor(np.load(\"data/vaccine_tensor.npy\"), **context)\n",
    "#print(tensor)\n",
    "#find_best_rank(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641c78f-0847-4825-b600-53402db1f2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
